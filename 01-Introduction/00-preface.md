# 생성형 인공지능 시대
## 들어가기
### 1. 개념정리
#### 1. LLM
LLM이란 "Large Language Model"의 약자로, 자연어 처리 분야에서 사용되는 기술입니다. LLM은 대량의 텍스트 데이터를 학습하여 문장 생성, 번역, 요약 등 다양한 자연어 처리 작업을 수행할 수 있습니다. LLM은 딥러닝 모델 중 하나인 "Transformer"를 기반으로 구현되며, 최근에는 GPT-3와 같은 대규모 LLM 모델이 주목을 받고 있습니다. LLM은 인간과 자연스러운 대화를 할 수 있는 인공지능 개발에 많은 도움을 주고 있습니다.  

GitHub Copilot에게 ```LLM을 한국말로 초등학생도 이해하기 쉽게 설명해주세요```라고 요청하자 아래와 같이 새로 설명을 해줍니다.
>GitHub Copilot: LLM은 "Language Model"의 약자로, 컴퓨터가 언어를 이해하고 생성하는 기술입니다. 예를 들어, 우리가 문장을 입력하면 LLM은 이를 이해하고 비슷한 문장을 생성할 수 있습니다. LLM은 많은 양의 텍스트 데이터를 학습하여 문장 생성, 번역, 요약 등 다양한 자연어 처리 작업을 수행할 수 있습니다. 이러한 기술은 인공지능 개발에 많은 도움을 주고 있습니다. 예를 들어, LLM을 사용하여 인간과 자연스러운 대화를 할 수 있는 챗봇을 만들 수 있습니다.

#### 2. 미세조정 또는 Fine-tuning
이래 내용은 역시 GitHub Copilot과 함께 만든 내용입니다. 
프롬프트는 ```인공지능 분야에서 Fine-tuning에 대해 설명하고 추가해서 알기 쉽게 한국어로 설명을 한 번 더 해주세요.``` 이었습니다.

>Fine-tuning은 인공지능 분야에서 사용되는 개념으로,이미 학습된 모델을 새로운 작업에 맞게 조정하는 과정을 말합니다. 기존에 학습된 모델은 대부분 대규모 데이터셋을 사용하여 다양한 패턴과 특징을 학습한 상태입니다. 그러나 특정 작업을 수행하기 위해서는 이러한 일반적인 모델을 특화시켜야 합니다.
>
>Fine-tuning은 미세한(Fine) 조정(Tuning)을 통해 기존 모델을 새로운 작업에 맞게 최적화하는 과정입니다. 이를 위해 새로운 작업에 필요한 데이터를 사용하여 기존 모델을 추가로 학습시킵니다. 이렇게 하면 모델은 새로운 작업에 더욱 적합한 특징을 학습하게 되며, 더 나은 성능을 발휘할 수 있습니다.
>
>예를 들어, 이미지 분류 작업을 위해 사전에 학습된 컨볼루션 신경망 모델을 사용한다고 가정해보겠습니다. 그러나 이 모델은 개와 고양이를 분류하는 작업에 사용되었기 때문에, 새로운 작업인 자동차와 비행기를 분류하는 데에는 적합하지 않을 수 있습니다. 이럴 때 Fine-tuning을 사용하여 기존 모델을 자동차와 비행기 분류 작업에 맞게 조정할 수 있습니다. 새로운 작업에 필요한 자동차와 비행기 이미지 데이터를 사용하여 모델을 추가로 학습시키면, 모델은 자동차와 비행기에 대한 특징을 더 잘 학습하게 되고, 더 정확한 분류를 수행할 수 있습니다.
>
>이렇게 Fine-tuning을 통해 기존 모델을 새로운 작업에 맞게 조정함으로써, 더 나은 성능을 얻을 수 있습니다.

하지만, Fine-tuning은 치명적인 약점도 있습니다.

>Fine-tuning은 인공지능 모델을 새로운 작업에 맞게 조정하는 유용한 방법이지만, 몇 가지 문제점과 어려움이 있습니다.
>
>- **데이터 부족**: Fine-tuning은 새로운 작업에 필요한 충분한 양의 데이터가 필요합니다. 이 데이터가 부족하면 모델은 새로운 작업에 대해 제대로 학습하지 못하고, 성능이 저하될 수 있습니다.
>
>- **과적합**: 새로운 작업에 대한 데이터가 매우 제한적인 경우, 모델은 이 데이터에 과도하게 적합하게 될 수 있습니다. 이는 모델이 새로운 데이터에 대해 일반화하는 능력을 저하시키며, 실제 세계에서의 성능을 저하시킵니다.
>
>- **카타스트로픽 포기**: Fine-tuning 과정에서 모델이 원래 학습했던 정보를 잊어버리는 현상을 카타스트로픽 포기라고 합니다. 이는 특히 새로운 작업의 데이터가 원래 작업의 데이터와 매우 다른 경우에 발생할 수 있습니다.
>
>- **최적화 어려움**: Fine-tuning은 모델의 파라미터를 새로운 작업에 맞게 조정하는 과정이므로, 이 과정에서 최적의 파라미터를 찾는 것이 어려울 수 있습니다. 이는 특히 모델의 구조가 복잡하고, 파라미터의 수가 많은 경우에 문제가 될 수 있습니다.

#### 3. 검색증강생성 또는 RAG(retrieval-augmented generation)
검색기반의 증강된 자료를 통해 원하는 내용을 생성해주는 것을 '검색증강생성' 또는 'RAG'라고 합니다. 'RAG'는 '알에이지'라고도 읽지만 '라그' 또는 '래그'라고들 합니다.  
'RAG'이 장점은 우수한 수준의 거대규모언어모델(LLM)을 그대로 잘 활용하면서, 참고할 자료를 제공해서 원하는 내용에 가까운 답을 찾아내게 하는 겁니다.  
0
GitHub Copilot에게 ```RAG에 대해서 설명해주고, 좀 더 쉽게 풀어서 이해를 도와줄 수 있는 표현을 추가해주세요.``` 라고 요청을 한 결과입니다.  

>검색증강생성 또는 RAG는 검색 기반의 증강된 자료를 활용하여 원하는 내용을 생성하는 기술입니다. RAG는 거대한 언어 모델인 LLM을 활용하면서, 추가로 참고할 수 있는 자료를 제공하여 더 정확하고 의미 있는 답변을 생성할 수 있도록 도와줍니다.
>
>예를 들어, RAG를 사용하여 "세계에서 가장 높은 산은 무엇인가요?"라는 질문에 답변을 생성한다고 가정해봅시다. RAG는 먼저 검색 엔진을 활용하여 관련된 자료를 찾습니다. 그런 다음, 이 자료를 기반으로 LLM을 사용하여 질문에 대한 응답을 생성합니다. 이렇게 함으로써, RAG는 검색 결과를 참고하여 더 정확하고 신뢰할 수 있는 답변을 생성할 수 있습니다.
>
>따라서, RAG는 LLM의 장점을 그대로 활용하면서도 검색 기반의 자료를 활용하여 더욱 풍부하고 정확한 내용을 생성할 수 있는 기술입니다.

생성형 인공지능이 초기에 보여준 '환각현상(Hallucination)'을 효과적으로 해결할 수 있는 방법으로 가장 많이 실질적으로 활용하고 있는 기술 가운데 하나입니다.

특히 이 방법은 기술의 발전과 변화가 빨라서 기존 이론이나 데이터가 수정될 필요가 있는 경우에 더욱 효과적일 수 있습니다. 가령 교과서로 삼고 있던 자료들이 변화가 필요한 경우에 미세조정(Fine-tuning)을 했다고 하더라도 미세조정에 제공한 자료가 수정되어야할 상황이라면 미세조정은 다시 새로운 자료를 통해서 이뤄져야 하는데, 기껏 잘 해놓은 미세조정이 또 틀어지는 위험이 검색증강생성에는 확연히 덜합니다.

#### 4. 거대언어모델(LLM)과 미세조정(Fine-tuning), 그리고 검색증강생성(RAG)

좀 더 쉽게 말하자면 'LLM'은 꽤 우수한 수학능력시험을 치른 수험생이라고 볼 수 있고, 'Fine-tuning'은 그 학생을 의대를 보내서 빡세게 공부시켜서 시험을 치르게 하는 것이라고 볼 수 있고, 'RAG'는 해당 수험생에게 참고할 자료를 주고 질문을 해서 오픈북 시험처럼 참고할 자료에서 답을 적게 하는 것이라고 보면 이해가 수월하지 않을까 합니다.  
'Fine-tuning'한 학생은 최근 자료를 몰라서 예전 교과서를 통해 답을 잘 할 수 있겠지만, 최신 자료 업데이트는 안되어 있을 수밖에 없고 최신 자료를 제공한다고 할 때 기존 학습자료와 차이가 있어 이 부분에 대한 별도의 조치를 취해줘야 합니다.  
'RAG'는 검색을 기반으로 하므로 얼마나 잘 검색결과를 가져오느냐가 생성을 위한 핵심요소가 되기에 '검색'이 무엇보다 중요합니다. 같은 자료를 줘도 답을 못찾는 사람이 있는 반면 검색을 아주 잘하는 사람을 보셨을텐데, 검색능력이 결과 생성에 핵심이 될 수밖에 없습니다.

### 2. 초보자들의 관심
초보자들이기에 명확한 이해가 없으면 여기저기에서 들리는 각종 개념과 언어의 홍수 속에서 뭘 해야 하나보다하고 방향을 잃을 때가 많습니다.  

정확한 개념 이해를 통해서 내가 뭘 해야 할 지를 아는 것이 매우 중요하기에 초보자들은 기술에 대한 관심이상으로 명확한 개념 이해를 통해 기초를 튼튼히 하는 게 매우 필요하지 않을까 싶습니다.

## 나가기
이 과정은 생성형 인공지능의 전반을 다루지 않습니다. 생성형 인공지능에 대한 활용에 오히려 관심을 둡니다.  

생성형 인공지능의 세밀한 영역은 그들에게 맡겨두고, 재빨리(Agile) 군더더기없이(Lean) 서비스를 만들고 이를 통한 기여와 보상을 기술적인 결핍에도 불구하고 가능하게 만드는 방법.  

본 과정은 여기에 초점을 두고 있습니다.  

본인이 하고 싶은 것이 인공지능 기술을 이해하고 발전시키는 것에 있는 지 인공지능 기술을 손쉽게 활용하는 데 관심이 있는 지를 잘 이해하는 것도 필요하지 않을까 싶습니다.

나만의 미세조정된 언어모델을 통해서만 서비스를 할 수 있다고 생각한다면 그건 생성형 인공지능의 최근 흐름에 비춰 오히려 무모한 게 아닌가 싶습니다. 충분한 준비가 얼마나 필요할지도 모르는 세상이며 그만큼 재빨리 세상이 변하고 있는 상황에서 미세조정은 어쩌면 준비와 실행에서 때늦은 실패를 향해 열심히 달려갈지도 모릅니다.